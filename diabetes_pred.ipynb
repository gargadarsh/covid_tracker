{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "import keras \n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "'''\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from mlens.metrics import wape, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"Data/diabetes_dataset.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = data.iloc[:,:-1],data.iloc[:,-1]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15)\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=x,label=y,feature_names=x.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning the data by replacing 0 \"skews\" with NaN and then the median values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:22:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { loss } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Creating the Model\n",
    "model_xgb = xgb.XGBClassifier(objective ='reg:squarederror', gamma=3.7, \n",
    "                             min_child_weight=14, loss=\"ls\", colsample_bytree=1, \n",
    "                             max_depth=4, learning_rate=0.05, alpha=7, \n",
    "                             n_estimators = 300, subsample=1)\n",
    "model_xgb.fit(x_train, y_train)\n",
    "predictions = model_xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:22:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { loss } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:22:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { loss } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:22:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { loss } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:22:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { loss } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:22:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { loss } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:22:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { loss } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:22:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { loss } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:22:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { loss } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:22:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { loss } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:22:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { loss } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Cross Validation accuracy: 0.7377389277389278\n",
      "Score: 0.745398773006135\n",
      "error: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "\n",
    "accuracy = cross_val_score(estimator = model_xgb, X = x_train, y = y_train, cv = 10)\n",
    "print(\"Cross Validation accuracy:\" ,accuracy.mean())\n",
    "\n",
    "score = model_xgb.score(x_train, y_train)  \n",
    "print(\"Score:\", score)\n",
    "\n",
    "error = wape(y_test, predictions)\n",
    "print(\"error:\", error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Import Feature Search\n",
    "\n",
    "params = {'alpha': 11, 'colsample_bytree': 1, 'gamma': 3.7, 'learning_rate': 0.05, \n",
    "'max_depth': 7, 'min_child_weight': 14, 'n_estimators': 299, 'subsample': 1}\n",
    "xg_reg = xgb.train(params=params, dtrain=data_dmatrix, num_boost_round=10)\n",
    "\n",
    "xgb.plot_importance(model_xgb)\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0.\n 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1.\n 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1.\n 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-afd2461a6966>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_gbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_gbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0macc_gbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_gbr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensor/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \"\"\"\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensor/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \"\"\"\n\u001b[0;32m-> 1172\u001b[0;31m         \u001b[0mraw_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1173\u001b[0m         \u001b[0mencoded_labels\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_prediction_to_decision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensor/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1125\u001b[0m             \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m         \"\"\"\n\u001b[0;32m-> 1127\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1128\u001b[0m         \u001b[0mraw_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensor/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensor/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    621\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0.\n 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1.\n 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1.\n 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "## GBC Model\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model_gbc = GradientBoostingClassifier( learning_rate=0.2, n_estimators=200, max_depth=5, subsample=1, verbose=False)\n",
    "model_gbc.fit(x_train,y_train)\n",
    "\n",
    "predictions = model_gbc.predict(x_test)\n",
    "\n",
    "acc_gbc = cross_val_score(estimator = model_gbr, X = x_train, y = y_train, cv = 10)\n",
    "print(\"GB_Acc : \", acc_gbc.mean())\n",
    "\n",
    "error = wape(y_test, predictions)\n",
    "print(\"error:\", error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:36:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { loss } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Best accuracy(XGB): 0.01385979242744576\n",
      "Best Parameters(XGB): {'learning_rate': 0.05, 'loss': 'ls', 'max_depth': 3, 'n_estimators': 200, 'subsample': 1}\n",
      "Best accuracy(GBR): 0.30103739273290187\n",
      "Best Parameters(GBR): {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 200, 'subsample': 1}\n"
     ]
    }
   ],
   "source": [
    "## Hyperparameter Optimization using Grid Search Cross Validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = [{'loss': ['ls','huber'], 'learning_rate': [0.01, 0.05, 0.07, 0.1, 0.15, 0.2], 'n_estimators': [200],'max_depth': [3, 5], 'subsample' : [1] },\n",
    "{'loss': ['ls','huber'], 'learning_rate': [0.05, 0.07, 0.2], 'n_estimators': [350],'max_depth': [6], 'subsample' : [1] },\n",
    "{'loss': ['ls','huber'], 'n_estimators': [100],'learning_rate': [0.1], 'max_depth': [4], 'subsample' : [1] }]\n",
    "\n",
    "#XGB model\n",
    "gs_xgb = GridSearchCV(estimator = model_xgb, param_grid = parameters, scoring = 'explained_variance', cv = 10, n_jobs = -1)\n",
    "gs_xgb.fit(x_train,y_train)\n",
    "print(\"Best accuracy(XGB):\", gs_xgb.best_score_)\n",
    "print(\"Best Parameters(XGB):\", gs_xgb.best_params_)\n",
    "\n",
    "#gbr MODEL\n",
    "gs_gbc = GridSearchCV(estimator = model_gbr, param_grid = parameters, scoring = 'explained_variance', cv = 10, n_jobs = -1)\n",
    "gs_gbc.fit(x_train,y_train)\n",
    "print(\"Best accuracy(GBR):\", gs_gbc.best_score_)\n",
    "print(\"Best Parameters(GBR):\", gs_gbc.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
